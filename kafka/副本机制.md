#### 副本机制

* 每个topic 都可以分为多个partition，并且多个partition 会均匀分布在集群的各个节点下。虽然这种方式能够有效的对数据进行分片，但是对于每个partition来说 ，都是单点的，当其中一个partition不可用的时候，那么这部分消息就没办法消费。所以kafka为了提高partition的可靠性而提供了副本的概念（Replica)，通过副本机制来实现冗余备份。

* ==每个分区可以有多个副本，并且在副本集合中会存在一个leader的副本，所有的读写请求都是由leader副本来进行处理。剩余的其他副本都作为Follower副本，Follower副本会从leader副本同步消息日志。==这个有点类似Zookeeper中leader和Follower的概念，但是具体实现方式还是有很大的差异。所以副本集会存在一主多从的关系。

* 一般情况下，==同一个分区的多个副本会被均匀分配到集群中的不同broker上，当leader副本所在broker出现故障后，可以重新选举新的leader副本继续对外提供服务。通过这样的副本机制提高了kafka集群的可用性。==

* **注意：kafka集群中的一个broker中最多只能有一个副本，leader副本所在的broker节点的分区叫leader节点，foolower副本所在的broker节点的分区叫follower节点**

* 创建带分区的命令

  ```sh
  sh kafka-topics.sh --create --zookeeper 192.168.131.3:2181 --replication-factor 3 --partitions 3 --topic testTopic
  
  ```

   ![img](%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6.assets/5c06f07548859df34a03c61ee3fbcf97.png)

* kafka 提供了数据复制算法保证

  * 如果leader 副本所在的broker节点宕机或者出现故障，或者分区的leader节点发生故障，这时候kafka会从follower副本中选择一个新的leader 副本。所以就会涉及到副本的leader选举。 
  * leader副本：响应clients端读写请求的副本
  * follower副本：被动地备份leader副本中的数据，不能响应clients端读写请求
  * ISR副本列表：包含了leader副本和所有leader副本保持同步的follower副本

* 如果判断是否于leader同步，和LEO和HW有关，所有的副本都有这个属性

  * LEO：即日志末端位移（log end offset），记录了该副本底层日志（log）中下一条消息的位移值。注意是下一条消息！也就是说，如果LEO=10。那么表示该副本保存了10条消息，位移值范围是[0,9]。另外Leader LEO 和follower LEO的更新是有区别的。

  * HW：即上面提到的水位值。对于同一个副本对象而言，其HW值不会大于LEO值。小于等于HW值的所有消息都被认为是 “已备份”的（replicated）。Leader副本和Follower副本更新HW的方式有区别的。
  *  `从生产者发出的一条消息首先会被写入分区的leader副本，不过还需要等待 ISR 集合中的所有follower 副本都同步完之后才能被认为已经提交，之后才会更新分区的 HW，进而消费者可以消费到这条消息 `

* 副本的协同

  * 写请求首先由leader副本处理，之后Follower副本会从leader 上拉取写入的消息。这个过程会有一定延迟，导致Follower副本中保存的消息少于leader副本，但是只要没有超出阔值都可以容忍。
  * 但是如果一个Follower 副本出现异常，比如宕机、网络断开等原因长时间没有同步消息，那么这个时候，leader就会把它踢出去。
  * kafka通过 ISR 集合来维护一个分区副本信息

*  加入isr集合的条件 

  * 副本所在节点必须维持有Zookeeper的连接
  * 副本最后一条消息的offset 与 leader 副本的最后一条消息的offset 之前的差值不能超过指定的阈值replicas.lag.time.max.ms，如果该follower在此时间间隔内一直没有追上过leader的所有消息，则该foolower 就会被剔除 ISR 列表

*  lastCaughtUpTimeMs标志 

  *  kafka副本管理器会启动一个副本过期检查的定时任务，这个任务会定期检查当前时间与副本的lastCaughtUpTimeMs的差值是否大于参数`replicas.lag.time.max.ms`的值，如果大于，则会把这个副本剔除ISR集合 

     ![img](%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6.assets/d12594aa48855b14f9cc67771d5b586f.png) 

*  当所有的replica都宕机了。那么会选择第一个 “活”过来的Replica作为Leader，而这个Replica不是ISR中的Replica，那即使它不保证已经包含了所有已commit的消息，它也会成为leader而作为consumer的数据源。 





* ##### 副本数据同步原理

  * 副本除了协同还有一个重要的机制，就是数据的同步，同步需要解决如下问题：

    > - 怎么传播消息
    > - 在消息发送端返回ack之前要保证多少个replica已经接受到这个消息

  * Producer在发布消息到某个partition时：

    * 先通过zk找到该partition 的Leader get/brokers/topics/<topic>/partition/2/state，然后无论该topic的replication Factor为多少 ,Producer只将该消息发送到该Partition的Leader。

    * ==Leader会将消息会将该消息写入其本地Log。每个Follower都从Leader pull 数据。这种方式上，Follower存储的数据顺序与Leader保持一致。==

    * Follower在收到该消息并写入其Log后，想Leader发送ACK。

    * 一旦Leader收到了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader会增加HW（Hight Water Mart） 并且向producer发送ACK

       ![img](%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6.assets/a9a453c63add23da1fe4ab5bafb6474f.png) 

  * 初始状态下，Leader 和 Follower 的HW 和LEO都是0，leader副本会保存remote LEO，也会被初始化为0，这个时候，producer没有发送消息，Follower会不断地给leader发送FETCH请求，但是因为没有数据，这个请求会被leader寄存，当在指定的时间之后会强制完成请求，这个时间配置是(replica.fetch.wait.max.ms)。如果在指定时间内producer有消息发送过来，那么kafka会唤醒fetch请求，让leader继续处理。

     ![img](%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6.assets/2e4d5542663840a72240231e01431988.png)

  * 数据同步处理会分**两种情况**， 这两种情况的从处理方式是不同的

    - **第一种**是leader处理完producer请求之后，follower 发送一个 fetch 请求过来

      ```doc
      生产者发送一条消息
      
      leader处理完producer请求之后，follower发送一个fetch请求过来，状态图如下：
      
      leader副本收到请求以后，会做几件事
      
      1、把消息追加到log文件，同时更新leader副本的leo
      2、尝试更新leader HW值，这个时候由于follower副本还没有发送fetch请求，那么leader 的remote LEO 仍然是0，leader 会比较自己的LEO以及remote LEO的值发现最小值是0，与HW值相同，所以不会更新HW
      follower fetch
      
      follower 副本发送fetch请求，leader副本的处理逻辑是
      1、读取log数据，更新remote LEO=0(follower还没有写入这条消息，这个值是根据follower的fetch请求中的offset来确定的)
      2、尝试更新更新HW，因为整个时候LEO和remote LEO 还是不一致，所以仍然是HW=0
      3、把消息内容和当前分区的HW值发送给follower副本
      follower副本收到response以后
      1、将消息写入到本地log，同时更新follower的LEO
      2、更新follower HW，本地的LEO和leader 返回的HW进行比较取小值，所以仍然是0
      第一次交互结束后，HW仍然是0，这个值会在下一次follower发起fetch请求时被更新
      
      follower发起第二次fetch请求，leader收到请求以后
      1、读取log数据
      2、更新remote LEO=1，因为这次fetch携带的offset是1
      3、更新当前分区的HW，这个是偶leader LEO 和 remote LEO 都是1，所以HW的值也更新为1
      4、把数据和当前分区的HW值返回给follower副本，这个时候如果没有数据，则返回为空
      follower副本收到response以后
      1、如果有数据则写本地日志，并且更新LEO
      2、更新follower的HW值
      
      
      ps：由上总结
      
      follower发起fetch，leader收到了做如下的事
      读取log数据，更新remote LEO（根据fetch请求的offset来确定）
      尝试更新HW，（也是根据fetch请求的offset来确定remoteLEO后，用remote LEO 和自己的LEO对比取最小)
      将消息内容（没有就为空）和当前分区的HW值发送给follower副本
      follower收到响应后做如下
      将消息（如果不为空）写入到本地log，同时更新follower的LEO
      更新follower的HW值，（本地的LEO和返回的HW取最小值）
      ```

      

      ![img](%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6.assets/f74a384a8116a49232146f8c37c2b6aa.png) 

    - **第二种**是follower 阻塞在leader 指定时间之内，leader 副本收到producer请求

      ```doc
      这种情况就是leader副本暂时还没有消息过， 所以follower的fetch会被阻塞，直到等待超时或者leader接受到新的数据。当leader收到请求以后会唤醒处于阻塞的fetch请求，处理过程基本和上面的说法一致。
      
      leader将消息写入本地日志，更新Leader的LEO
      唤醒follower的fetch请求
      更新HW
      ```

  

  

*   数据丢失原理 

  * Kafa使用HW和LEO的方式来实现副本数据的同步，本身设计挺好，但是这在这个地方会存在一个数据丢失的问题，当然这个丢失只出现在特定的背景下，HW的值在新的一轮fetch中才会被更新，在这个过程有可能会出现数据丢失。

  * 设定ISR中的最小副本数是多少，默认为1（在server.properties中配置），并且acks参数设置为 -1 (表示需要所有副本确认，Producer可配置)时，此参数才生效

  * 表达的含义是，至少需要多少个副本同步才能表示消息是提交的，所以当min.insync.replicas=1的时候，一旦消息被写入leader端log即被认为是 “已提交” ，==而延迟一轮FETCH RPC更新HW值得设计使得follower HW 值是异步延迟更新的，倘若在这个过程中leader发生变更，那么成为新leader的follower的HW值就有可能是过期的，使得clients 端认为是成功提交的消息被删除。==

     ![img](%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6.assets/95e96a828c9bef90250b99547a8730fb.png)

    

  * 解决方案

    * 在kafka0.11.0.0版本之后，引入了一个leader epoch 来解决这个问题，所谓的leader epoch实际是一对值（epoch，offset），epoch代表leader的版本号，从0开始递增，当leader发生过变更，epoch就 +1 ，而offset则是对应这个epoch版本的leader写入第一条消息的offset
    * 比如：（0,0）,（1,50），表示第一个leader从offset=0开始写消息，一共写了50条，第二个leader版本号是1，从offset=50开始写，这个信息会持久化到对应的分区的本地磁盘上，文件名是/tmp/kafka-log/topic/leader-epoch-checkpoint
    * leader broker 中会保存这样一个缓存，并且定期写入到checkpoint文件中
      当leader写log时它会尝试更新整个缓存；
    * 如果这个leader首次写入消息则会在缓存中增加一个条目；否则就不做更新。
    * 而每次副本重新成为leader 时会查询这部分缓存，获取出对应leader版本的offset

  * 原理

    * Follower宕机并且恢复之后，有两种情况，如果这个时候leader 副本没有挂，也就是意味着没有发生leader选举，那么Follower恢复之后并不会去截断自己的日志，而是先发送一个OffsetForLeaderEpochRequest请求给到leader副本，leader副本收到请求之后返回当前的LEO。
    * `如果Follower副本的leaderEpoch和Leader副本的epoch相同，leader的LEO只可能大于或者等于Follower副本的LEO值，所以这个时候不会发生截断。`
    * 如果Follower副本和leader副本的epoch值不同，那么leader副本会查找Follower副本传过来的epoch + 1在本地文件中存储的StartOffset返回给Follower副本，这样就避免了数据丢失的问题。（和上一条原理类似）
    * 如果leader副本宕机了，重新选举新的leader，那么原本的Follower副本就会变成leader，意味着epoch从0变成了1，使得原本Follower副本中LEO的值得到了保留

*  Leader副本的选举过程 

  * kafka Controller 会监听Zookeeper的/brokers/ids节点路径，一旦发现有broker挂了，执行下面的逻辑。这里不考虑kafkaController所在broker挂了的情况，kafkaController挂了，各个broker会重新选举出新的kafkaController
  * 重新选举leader策略如下：

    * 优先从ISR列表中选出第一个作为leader副本，这个叫优先副本，理想情况下有限副本就是该分区的leader副本
    * 如果ISR列表为空，则查看该Topic的unclean.leader.election.enable配置。
    * unclean.leader.election.enable：为true则表示允许非ISR列表的副本作为leader，那么此时意味着数据可能丢失
    * 为false则表示不允许，直接抛出NoReplicaOnlineException异常，造成Leader副本选举失败。
    * 如果上述配置为true，则从其他副本中选出一个作为leader副本，并且ISR列表只包含该Leader副本。一旦选举成功，则将选举后的leader和ISR和其他副本信息写入到该分区的对应的zk路径上。
      