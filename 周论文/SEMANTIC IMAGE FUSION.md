# SEMANTIC IMAGE FUSION

**摘要：**用于评估的图像融合方法和度量标准通常使用基于像素或低级特征。但是，对于许多应用，图像融合的目的是有效地组合输入图像的语义内容。本文提出了一种使用预先训练的CNN网络体系结构进行视觉内容语义组合的新颖系统。我们提出的语义融合是通过融合图像输入的梯度更新 (所谓的图像优化) 通过融合顶层特征图输出 (针对每个输入图像) 而启动的。基于简单的 “选择最大值” 和 “局部多数” 的融合规则用于特征图融合。这提供了一种简单的方法来组合层输出，从而提供了一种独特的框架来融合单通道和彩色图像，该分解在预先训练的分类中，因此与语义融合保持一致。此外，每个输入图像的类激活映射用于在更高级别上组合语义信息。所开发的方法能够提供与最新方法同等的低级融合性能，同时提供独特的体系结构来组合来自多个图像的语义信息。

## 一.介绍

图像融合是将多个图像组合成一个单一的图像，旨在组合所有来源的最重要的视觉信息 [1]。图像融合的动机是需要在多传感器和多摄像机应用 (如遥感 [2]，医学 [3] 和监视 [4]) 中改善视觉表示，可视化，场景理解和态势感知。图像融合是由设备和传感器的限制驱动的。例如，并非所有重要的视觉信息都可以由一种类型的传感器 (例如IR、可见等) 或在一个单一的拍摄设置 (即聚焦、角度等) 内捕获。

此外，互补的成像方式共存于诸如遥感和医学之类的领域中，这些领域包含非常不同且重要的视觉信息。因此，来自所有图像源的所有视觉信息的有效组合是图像融合的目标。这样的组合图像通常对于诸如场景理解和目标识别之类的后续任务有效。

在过去的半个世纪中，图像融合一直是一个高度研究的领域。在此期间，图像融合是在或决策级别，特征级别和像素级别执行的 [5]。基于简单信号处理的像素级图像融合在过去的几十年中已经取得了出色的结果，并且由于其高效率且缺乏对训练数据的需求而继续使用 [5]。像素级融合可以进一步分为基于分解的方法或基于稀疏表示 (SR) 的方法 [5]。在基于分解的技术中，使用复杂小波 (dt-cwt) [1]，离散小波变换 (DWT) [6] 和contourlet变换 [7] 等方法将输入图像分解为变换域。在变换域中，使用适当定义的融合规则 (例如加权平均 [8] 和 “选择最大” [9]) 组合系数。

最近，最先进的图像融合技术集中在基于网络的方法的使用上 [10,11，12,13，14,15，16,17]。由于需要训练数据的要求，这些方法通常以红外/可见融合 [12,13]，遥感 (多光谱) [14] 和多焦点区域 [15,16] 的最新结果为重点。最近的工作也集中在通用图像融合方法上，该方法可以有效地组合所有这些领域中的多个源 [17]。只有极少数以前开发的融合方法利用语义信息进行图像融合 [18,19]。但是，这些方法并未像我们的工作中提出的那样使用联合分类和类激活图来语义地融合输入源。这些先前的作品也仅以非常有限的方式使用语义信息。

### 1.1贡献

我们工作的贡献和特点总结如下：

* 提出了一种无监督融合技术，可以使用基于选择最大和多数滤波器的融合规则 (使用图像优化) 来组合预先训练的低级特征图的输出。
* 使用类激活图的无监督语义融合方法。
* 一种无监督的融合方法，它将使用类激活映射的直接语义融合与低级网络层输出的组合 (即结合上述两种方法) 结合在一起。



## 二.基于图像优化的特征图融合

用于图像优化的预训练网络中基于特征图的损失函数已广泛用于神经样式传递 (NST) [20] 和 “Deep Dream” 方法 [21]。该领域由Gatys等人在NST的开创性工作发起 [22]。Gatys的NST系统通过使用预先训练的卷积神经网络 (CNN) 的图像优化方法，将先前开发的纹理合成方法 [23,24] 应用于两个图像 (“内容” 图像和 “样式” 图像) 的组合: VGG19 [25]。尽管这些方法提供了惊人的视觉效果，但它们尚未用于一般图像处理应用，例如图像融合和去噪。使用图像优化的NST可以通过使用损失函数的最小化生成输出样式传输图像 (i ∗) 来总结:

其中 I∗ 是输出图像，Is 是“风格”图像，Ic 是“内容”图像，α 和 β 是损失权重参数。内容和风格损失（Lc，Ls）比较风格和内容图像（Is，Ic）之间的内容和风格表示。作为初始步骤，这两个图像中的每一个都被分解为 VGG19 CNN 网络 [25] 的层输出。这两个损失被计算为两个图像的层输出之间的功能比较。然后通过网络使用图像 w.r.t 上的梯度通过梯度更新来实现图像优化。总损失 Ltotal。自最初的论文以来，已经报道了 NST 的许多更新和优化。 Li 和 Wand [26] 提出了一种基于马尔可夫随机场 (MRF) 的损失函数，可以生成更合理的视觉输出。计算优化的 NST 方法包括 Johnson 等人。 [27] 和 Ulyanov 等人。 [28]。这些方法在原理上类似于 Gatys 的方法，但使用预训练网络的单个前向传递来实现。 Multiple-Style-PerModel NST 方法包括 Dumoulin 等人。 [29]，李等人。 [30] 以及张和达纳 [31]。最后，GAN [32]、CycleGAN [33] 和图像转换器 [34] 最近已用于 NST。尽管该领域已经取得了许多进展，但就其结果的质量而言，Gatys 方法仍然被大多数研究人员认为是黄金标准 [20]。因此，尽管它没有经过计算优化或基于更复杂的变换（GAN 或图像变换器），但我们的工作基于这种类型的图像梯度更新，因为它提供了出色的结果，并且在概念上易于理解和操作。我们开发的方法的计算优化可以作为未来的工作来实现。

### 2.1基于图像优化的图像融合融合规则和损失函数

上述图像优化方法几乎完全用于神经样式转移。但是，我们提出了这种用于图像融合的特征图图像优化方法。对于图像融合，已经在各种预先训练的CNN网络的详尽的层子集集合上测试了各种融合规则和损失函数。发现跨单层进行损失会产生最有效的结果。此外，可以认识到，==随着层离输入图像越来越远，语义信息也会增加。这提供了这样的可能性，即在这些层上的融合可以组合越来越多的抽象语义信息。==

==然而，这样的高级层具有降低的分辨率，因此增加了特征图中每个特征的空间支持。发现融合此类层会产生不需要的伪像，例如条带。==发现与输入图像具有相同分辨率的层给出了最有效的结果 (例如，VGG19 CNN的前两层)。==尽管已经考虑了非常复杂的融合规则和损失函数，但发现在大多数情况下，简单的选择最大融合规则与l2损失函数相结合给出了最佳结果。==这种选择最大融合规则的选择和效用是由其在小波变换域 [1,6] 中的使用所激发的，即大幅度系数 (或特征图输出) 与感知上重要的内容相关。算法1说明了在基于特征图的图像融合方法中使用的梯度更新方法。该算法基于更新输入图像i ∗ 的关键概念，该输入图像i ∗ 通过相对于损失函数 (例如 (6) 的梯度更新而输入到网络N (如在样式传递方法和deep dream方法中实现的那样)。样式转移方法内的损失函数是通过内容和样式图像输入的比较定义的 “内容” 和 “样式” 损失的加权组合。DeepDream方法 [21] 中的损失函数仅基于所选网络输出，层或层输出的绝对幅度。我们的融合损失函数在 (4) 中给出。这只是融合层输出 (在优化循环之外仅计算一次) 和迭代层输出特征图F之间的L2范数距离。在 (3) 中定义了实际的图像融合优化过程，该过程与NST方程 (1) 非常相似 (但是输入图像是要融合的图像I0和I1，而不是样式和内容图像: is和Ic)。

#### 2.1.1损失函数

## 三.使用类激活映射 (CAM) 的语义融合

在CNN中使用更抽象的层理论上提供了使用上述图像优化方法在语义上融合图像的能力。但是，由于这些特征图具有非常有限的空间分辨率，因此这种融合会导致明显的基于边缘的伪影。因此，我们选择利用类激活映射 (cam)，该映射给出了每个像素在生成给定类的分类中的相关性的空间映射。

CAMs首先由Zhou等人引入 [35]，并根据c类通过CNN最后一层的输入图像的输出权重之和生成重要空间映射。这种方法被推广到使用反向传播的类梯度梯度凸轮 [36]。这些方法已使用诸如Eigen-CAM [37]，使用视觉变压器 [38] 的Grad-CAM等方法进行了进一步扩展。但是，对于我们的工作，Grad-CAM的映射给出了最佳结果 (由于它们的空间一致性)。给定Selvaraju等人对Grad-CAM映射的定义。[36] 空间映射 (与输入图像相同的分辨率) 可以表示为Ml c(x，y)，其中c是所考虑的类，l是分析的层 (通常是最接近实际分类层的空间层)。我们发现，使用最低分辨率的特征图，映射给出的空间定位最少。使用更高分辨率的特征图层可以提供更好的空间定位，但不太准确地反映抽象类激活的较低 (更抽象) 层。因此，我们将最低的三个空间层组合如下:

## 结论

本文定义了四种新颖的融合方法，它们利用: 图像优化; 选择最大和多数过滤器融合规则; 和用于语义融合的类激活映射。图像优化方法能够实现使用常规图像融合度量在多个领域中测得的最新图像融合结果。此方法也可直接扩展到彩色图像 (历史上不是图像融合的主要焦点)。此外，基于CAM的方法可以首次直接利用来自每个融合图像中顶部分类的类的语义信息来生成真正的语义级别图像融合。据推测，组合对一组图像的分类很重要的区域将最有效地组合来自输入图像的语义信息。以这种语义上有意义的方式组合的图像被显示为保留了两个图像中的重要语义信息。此方法可以轻松扩展到多个图像，并融合每个图像中的前5个类。