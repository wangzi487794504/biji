 # EMFusion: An unsupervised enhanced medical image fusion network 

​                                                                                                        EMFusion：一种无监督的增强型医学图像融合网络 

 **摘要：**现有的图像融合方法总是对不同的模态医学图像使用相同的表示。否则，他们通过主观定义要保留的特征来解决融合问题。然而，它导致独特信息的失真，并限制了融合性能。针对这些局限性，本文提出了一种无监督的增强医学图像融合网络。我们同时执行表层和深层约束以增强信息保存。表面水平约束基于显着性和丰度度量，以保留主观定义的直观特征。在深层约束中，基于预先训练的编码器的唯一通道客观地定义了唯一信息。此外，在我们的方法中，融合结果的色度信息也得到了增强。这是因为我们使用结构图像 (例如MRI) 中的高质量细节来减轻功能图像 (例如PET，SPECT) 中的马赛克。定性和定量实验均证明了我们的方法优于最新的融合方法。 

### 一.介绍

 随着成像方式的发展，医学成像可以提供对身体组织和结构的良好理解。由于其在诊断、治疗计划和手术导航中的广泛应用[1]，医学影像继续受到越来越多的关注。根据成像技术，多模态医学图像通常关注不同类别的信息，分为结构信息和功能信息[2]。结构系统提供结构和解剖信息。例如，计算机断层扫描 (CT) 可检测密集结构，例如骨骼和植入物。磁共振成像 (MRI) 提供软组织信息，如图 1.1 所示。功能系统包括正电子发射断层扫描 (PET) 和单光子发射计算机断层扫描 (SPECT)。 PET表征肿瘤功能和代谢，SPECT反映组织和器官血流[3]。考虑到单模态图像的局限性，图像融合旨在将多模态图像中的典型和互补信息融合到单个输出中，以实现更好的人类视觉感知和自动检测[4,5]。
      为了保留源图像中的信息，需要从源图像中提取许多特征作为综合表示，并将它们融合得到融合图像。为此，许多传统方法提出了各种分解方式。然后，他们设计融合规则来融合分解的部分，并将这些部分转换为融合结果。一方面，分解方式和融合规则的设计既费时又复杂。另一方面，手工融合规则需要相同的表示/分解方式；虽然这是不合适的，因为源图像具有不同的模态。 

 在许多基于深度学习的方法中，不同的表示是通过神经网络实现的。通过端到端模型可以避免融合规则的设计。然而，由于医学图像融合缺乏ground truth，如何训练这样的端到端模型是一个重要的问题。一些方法通过使用多焦点数据进行监督学习来解决它，而多焦点和医学图像在本质上是不同的。其他无监督方法通过定义要保留的独特特征来解决它。然而，这些独特的特征是根据视觉感知主观定义的（详细描述将在第 2 节后面讨论）。手工特征的不准确和不完整导致真实独特信息的失真。上述分析促使我们在为多模态图像设计使用不同表示的端到端无监督模型时找到唯一信息的客观定义。

​       此外，从图 1 可以看出，功能性医学图像（例如 PET/SPECT 图像）本质上存在低信噪比 (SNR) 和有限空间分辨率的问题。令人不满意的图像质量受到一些退化因素的影响，包括物理和硬件限制以及软件问题[6]。马赛克PET和SPECT图像给功能信息识别带来困难，降低了检测精度。相比之下，MRI 图像包含高质量的纹理细节。如果它们可以用于增强功能图像和缓解马赛克，融合结果对于自动检测将更具价值。

![img](http://47.103.213.244/wp-content/uploads/2022/10/image-21.png)

<center>图 1. 多模态医学图像示例。从左到右：CT、MRI、PET 和 SPECT 图像。</center>

 为了解决上述挑战，我们提出了一种新的融合方法，称为增强医学图像融合网络 (EMFusion)。拟议的EMFusion的特点/贡献总结如下:
            1.我们提出了一种用于医学图像融合的端到端无监督网络。它同时执行表层和深层约束以保存信息。
            2.在表面水平上，我们通过综合考虑显着性和丰度来测量源图像的活动水平。不同的表示/测量方式更适合多模态图像。
            3.在深层约束中，通过神经网络客观地衡量唯一性。因此，它进一步增强了独特信息的保存。
            4.EMFusion不是直接将色度信息保留在功能图像中，而是通过融合网络生成色度信息。MRI图像的纹理细节用于减轻马赛克，从而增强色度信息。 

### 二.相关的工作

 学者们提出了多种传统的医学图像融合方法。根据分解方案，这些方法可以分为六类：（i）基于金字塔的方法[7-9]； (ii) 基于小波的方法[10]，包括小波[11]、离散小波[12]、平稳小波[13]、双树离散小波[14]、提升小波[15]等； (iii) 基于稀疏表示的方法[16-18]； (iv) 基于子空间的方法，包括主成分分析（PCA）[19,20]、非负矩阵分解（NMF）[21]、独立成分分析（ICA）[22]等； (v) 基于显着特征的方法[23-25]； (vi) 其他方法，包括curvelet [26]、shearlet [27]等。
      在这些方法中，不可避免地需要设计一些融合规则来生成权重图。这些权重图用于融合分解的子部分或系数。最后，通过逆变换生成融合结果。然而，设计分解方式和融合规则既费力又复杂。
      此外，这些方法对不同模态的图像使用相同的表示，并旨在保留相同的特征，例如高频信息，边缘等。但是，在多模态图像中，生命信息差异很大。例如，CT图像中的密集结构以对比度反映，而PET/SPECT图像中的功能信息以颜色表示。因此，对于多模态图像使用相同的表示是不合适的。
基于生成对抗网络 (GANs)，DDcGAN [31] 在生成器和两个判别器之间建立了对抗网络，以使融合结果与两种类型的源图像无法区分。Huang等人通过构建多生成器多鉴别器条件GAN提出了MGMDcGAN [4]。第一个cGAN生成真实的融合图像，第二个cGAN增强密集结构的信息，同时防止功能信息被掩模削弱。此外，还提出了几种统一的融合网络 [32-34]。其中，IFCNN [34] 是一种应用 [29] 中的训练方法的监督方法。这些方法通过主观地预先定义独特的特征来保存信息。此外，它们仅使用神经网络来融合亮度通道和MRI图像，而色度通道则直接保留而无需处理。MRI图像中清晰的纹理细节被忽略，没有被充分利用。因此，功能图像中的马赛克严重模糊了融合结果。

在这项工作中，我们提出了一个端到端的无监督网络。除了表面级约束之外，它还执行深层约束以增强对唯一信息的保存。此外，通过网络生成色度通道以减轻马赛克。 

### 三.提出的方法

 在本节中，我们通过分析多模态医学图像的特征来提供问题表述。然后，介绍了表层和深层约束的细节。最后给出了融合网络的损失函数和网络架构。**我们将源图像表示为大小为 𝐻 × 𝑊 × 𝐶𝑎 的 𝐼𝑎 和大小为 𝐻 × 𝑊 × 𝐶× 的 𝐼𝑏**，其中 𝐻 和 𝑊 分别表示高度和宽度。𝐶 为通道数。我们的目标是学习 (𝐼𝑎，𝐼𝑏) 和 𝐼𝑓 之间的映射。𝐼𝑓 是大小为 𝐻 × 𝑊 × 𝐶𝑓 其中 𝐶𝑓 = max(𝐶𝑎，𝐶𝑏) 的融合图像。
        对于多模态医学图像，融合任务包括以下典型任务 :( i) CT和MRI图像融合; (ii) PET和MRI图像融合; (iii) SPECT和MRI图像融合。**对于PET/SPECT图像，我们的目标是保留功能 (颜色) 信息。**由于它们的色度信息在MRI图像中不可用，因此我们将它们传输到YCbCr空间中，并将色度信息分离到Cb和Cr通道中。然后，将Y (亮度) 通道与MRI图像融合。融合图像应保持Y通道的强度分布。在CT图像中，生命信息是具有高像素强度/显着性的密集结构 (例如骨骼和植入物)。在MRI图像中，保留丰富的纹理更有价值。基于以上分析，这些图像的特征主要有两种形式: 像素强度和纹理。一方面，融合图像应保持显着的像素强度，以保留密集的结构或功能信息。另一方面，融合图像应保持丰富的纹理以保留软组织信息。因此，我们根据显著性和丰度进行测量。根据测量结果，我们在融合图像和源图像之间分配相似性约束 (稍后在第3.2节中讨论)。由于它在图像级别上，因此我们也将其称为曲面级别约束。 

<img src="http://47.103.213.244/wp-content/uploads/2022/10/image-22.png" alt="img" style="zoom: 50%;" />

情况，我们进行了补充和客观的测量，以增强独特信息的保存。考虑到神经网络可以提取各种特征作为替代，我们根据编码器网络提取的特征图定义唯一性。提取的融合结果的独特特征应与CT/PET/SPECT图像保持相似。由于此约束基于提取的特征，因此我们将其称为深层约束。表层和深层约束相结合，相互补充。此外，我们希望在MRI图像中使用丰富的细节来减轻PET/SPECT图像中的马赛克。换句话说，MRI图像有望增强Cb和Cr通道。根据公式。(1)，由于Y通道是RGB通道的线性组合，因此其增强可以促进RGB通道的增强，这也将在Cb和Cr通道中显示。基于它，我们直接生成RGB图像，而不是Y通道，如图2所示。在转换后的YCbCr通道上执行表面级约束。这样，后续的通道合并和空间转换也可以保存在我们的方法中。这样，我们的方法也可以省去后续的通道合并和空间转换。

损失函数可以定义如下：其中，**surface**和 **deep**分别表示表层和深层约束。chro是Cb和Cr通道的相似性约束，以保留色度信息。𝛼 和 𝛽 是控制权衡的超参数。

<img src="http://47.103.213.244/wp-content/uploads/2022/10/image-24.png" alt="img" style="zoom:80%;" />

我们假设𝐼𝑎 是 CT/PET/SPECT 图像，𝐼𝑏 是相应的 MRI 图像（𝐶𝑏 = 1）。由于希望保留显着像素强度和丰富的梯度，我们对𝑌𝑎和𝐼𝑏进行显着性和丰度测量。当𝐼𝑎是PET/SPECT图像时，𝑌𝑎是𝐼𝑎的Y通道；而当 𝐼𝑎 是 CT 图像时，𝑌𝑎 = 𝐼𝑎。

显着性测量定义为：

<img src="http://47.103.213.244/wp-content/uploads/2022/10/image-25.png" alt="img" style="zoom:50%;" />

其中𝜏是筛选显着区域的阈值。 Sign(·) 是符号函数。下标 𝑖 和 𝑗 表示像素位于第 𝑖 行和 𝑗 列。

具有更多纹理细节的区域从信息论的角度会显示出更大的信息量 (更大的熵) [35]。尽管熵和梯度都可以评估纹理细节的丰度，但是熵具有梯度所没有的优势。如CT图像所示，它在密集结构的边缘上包含一些具有较大值的梯度。而在其他地区，梯度稀疏且小得多。如果使用梯度作为测量标准，则测量结果将被边缘严重误导。相反，熵是通过图像中每个灰度级的概率分布来测量的。它考虑了整体像素强度分布，并且不受稀疏大梯度的影响。为此，我们使用熵来测量丰度，其数学定义

![img](http://47.103.213.244/wp-content/uploads/2022/10/image-26.png)

其中𝜆是控制两种测量方式之间权衡的超参数。

然后，我们使用活动分数来分配它们的重要性权重𝜔𝑎和𝜔𝑏。我们依靠重要性权重来分别约束融合图像和两个源图像之间的相似性。重要性权重越高，融合后的图像与对应的源图像的相似度就应该越高。一方面，𝜔𝑎和𝜔𝑏之间的数值大小关系应该与𝑠𝑎和𝑠𝑏之间的数值大小关系一致。另一方面，权重应该满足条件𝜔𝑎 + 𝜔𝑏 = 1 和 0 ≤ 𝜔𝑎，𝜔𝑏 ≤ 1。因此，我们根据 softmax 函数分配 𝜔𝑎 和 𝜔𝑏：

![img](http://47.103.213.244/wp-content/uploads/2022/10/image-27.png)

 对于相似性约束，我们使用结构相似性指数测度 (SSIM) [36] 和均方误差同时约束高频和低频信息的相似性: 

![img](http://47.103.213.244/wp-content/uploads/2022/10/image-28.png)

 𝑋和𝑍是大小为𝐻×𝑊的图像。 𝜉 是一个超参数。 ‖⋅‖𝐹 表示 Frobenius 范数。与通用图像质量指数（UIQI）[37]相比，SSIM更稳定，因此有利于神经网络训练。 

![img](http://47.103.213.244/wp-content/uploads/2022/10/image-29.png)

 如公式中所定义。(3)，在显着性活动测量中只能检测和考虑大于 𝜏 的像素强度。它限制了显着性低的区域的信息保留。相比之下，根据公式。(5)，EN将所有值考虑在内，无需筛选即可测量丰度。因此，𝐼𝑏 中的所有纹理细节都被考虑在内，而 𝐼𝑎 中的一些信息被省略了。为了更完整和客观地定义 𝐼𝑎 中的唯一信息，我们执行深层次的定义。根据唯一性的定义，𝐼𝑎 的唯一信息只有在 𝐼𝑎 中，没有在 𝐼𝑏 中。如果可以通过特定的转换从 𝐼𝑏 获取 𝐼𝑎 中的信息，则此信息不是 𝐼𝑎 所独有的。因此，我们将 𝐼𝑎 的唯一信息定义为无法从 𝐼transferred传输的功能。为此，我们首先学习一个转换 𝑓𝑇，该转换将 𝐼transfers转换为伪 𝐼𝑎，称为 ̃ 𝐼𝑎，即 ̃ 𝐼= 𝑓𝑇 (𝐼𝑏)。̃ 𝐼𝑎 应尽可能与 𝐼𝑎 相似，以覆盖尽可能多的公共信息，如图3所示。一个名为TransNet的网络被训练学习 𝑓𝑇，其中输入为 𝐼𝑏，输出为 ̃ 𝐼。TransNet的网络体系结构如图4所示。根据公式定义其损失函数来约束 ̃ 𝐼𝑎 和 𝐼𝑎 之间的相似性。 