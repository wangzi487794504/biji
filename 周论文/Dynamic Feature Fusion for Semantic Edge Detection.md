# Dynamic Feature Fusion for Semantic Edge Detection

​                                                                                                                                           动态特征融合语义边缘检测

**摘要：**如果多尺度特征融合良好，可以大大提高语义边缘检测的效率。然而，目前流行的语义边缘检测方法采用固定权值的融合策略，强制图像中不同的语义共享相同的权值，使得所有图像和位置的通用权值不考虑其不同的语义或局部上下文。在这项工作中，我们提出了一种新的动态特征融合策略，该策略自适应地为不同的输入图像和位置分配不同的融合权重，这是通过一个权值学习器根据特定的输入条件，为特征图的每个位置在多个层次的特征上提供适当的融合权重来实现的。这样，可以更好地考虑特征图和输入图像在不同位置所产生的差异，从而有助于产生更精确和更尖锐的边缘预测。通过在Cityscapes和SBD上的综合实验，我们证明了我们的新的动态特征融合模型优于固定权重融合模型和直接定位不变权重融合方法。而且我们的方法优于所有现有的方法，实现了sota。

## 介绍

语义边缘检测 (SED) 的任务旨在检测视觉显着边缘并识别其类别，或者更具体地说，定位利用低级特征的精细边缘，同时识别具有抽象高级特征的语义类别。深度CNN模型实现这两个目标的一种直观方法是通过融合模型将高级语义特征与低级类别不可知的边缘特征集成在一起，该融合模型通常遵循固定权重的融合策略，与输入无关，如图1中的第一行所示。在许多现有的深度SED模型中 [Yu等人，2017; Liu等人，2018; Yu等人，2018]，通过1 × 1卷积实现多级特征的固定权重融合，其中学习的卷积核用作融合权重。但是，这种融合策略无法充分利用多级信息，尤其是低级特征。这是因为，首先，它将相同的融合权重应用于所有输入图像，并忽略它们在内容，照明等方面的变化。需要自适应地处理特定输入的独特属性，以揭示微妙的边缘细节。此外，对于同一输入图像，相应特征图上的不同空间位置传达不同的信息，但是固定权重融合方式将相同的权重应用于所有这些位置，而不管它们的不同语义类别或对象部分。这将不利地迫使模型学习所有类别和位置的通用融合权重。因此，会导致对高级特征的偏见，并且多级响应融合的功能会大大减弱。

在这项工作中，我们提出了一种动态特征融合 (DFF) 方法，该方法将自适应融合权重单独分配给每个位置，旨在生成与每个图像的特定内容相适应的融合边缘图，如图1中的底部行所示。特别是，我们设计了一种新颖的位置自适应权重学习者，该学习者根据多级响应图的特征图内容积极学习自定义的特定于位置的融合权重。如图1所示，将低级特征 (Aside1〜Aside3) 和一个高级特征 (Aside5) 合并以产生最终的融合输出。低级特征图对精细细节 (例如对象内部的边缘) 具有很高的响应，而高级特征图则较粗，并且仅在对象级别的边界处表现出很强的响应。这个位置自适应权重学习者为每个单独的位置定制融合权重。例如，对于马的边界，融合权重偏向于低级特征，以充分利用精确定位的边缘。对于马的内部，将更高的权重分配给高级功能，以抑制对象内部的零碎和琐碎边缘响应。

提出的DFF模型由两个主要组件组成: 具有归一化器的特征提取器和自适应权重融合模块。特征提取器主要将多级响应缩放到相同的幅度，为下流融合操作做准备。自适应权重融合模块执行以下两种计算。首先，它根据图像内容动态生成特定于位置的融合权重。然后，应用特定于位置的融合权重来主动融合高层和低层响应图。自适应权重融合模块能够充分挖掘多级响应 (尤其是低级响应) 的潜力，从而为每个位置产生更好的融合输出。

总而言之，我们的主要贡献是: • 这项工作首次揭示了SED流行的固定权重融合的局限性，并解释了为什么它不能像预期的那样产生令人满意的融合结果。• 我们提出了动态特征融合 (DFF) 模型。据我们所知，在SED的研究领域中，学习以输入内容为条件的自适应融合权重以合并多级特征是第一项工作。提出的DFF模型实现了SED任务的最新技术。

## 相关工作

[Hariharan et al., 2011] 首次引入了类别感知语义边缘检测任务。它通常作为一个多类问题来解决 [Hariharan et al., 2011; Bertasius 等人，2015 年； Bertasius 等人，2016 年； Maninis et al., 2016] 首先，其中只有一个语义类与每个定位的边界像素相关联。从 CASENet [Yu et al., 2017]，研究人员开始将这项任务作为一个多标签问题来解决，其中每个边缘像素可以同时与多个语义类相关联。最近，基于深度学习的模型，例如 SEAL [Yu et al., 2018] 和 DDS [Liu et al., 2018]，进一步将语义边缘检测的性能提升到了最新的水平。采用固定权重融合的传统可以追溯到 HED [Xie and Tu, 2015]，其中采用加权融合层（由 1×1 卷积层实现）来合并边输出。 RCF [Liu et al., 2017] 和 RDS [Liu and Lew, 2016] 遵循这个简单的策略来执行与类别无关的边缘检测。 CASENet [Yu et al., 2017]、SEAL [Yu et al., 2018] 和 DDS [Liu et al., 2018] 使用 K-grouped 1×1 卷积层扩展了该方法，以生成 K 通道融合激活地图。在本文中，我们证明了上述固定融合策略不能充分利用多尺度响应来产生更好的融合输出。相反，我们提出的自适应权重融合模块使网络能够主动学习以个人输入内容为条件的位置感知融合权重。卷积神经网络中的多级表示已被证明在许多视觉任务中有效，例如对象检测 [Liu et al., 2016; Lin 等人，2017 年]，语义分割 [Long 等人，2015 年； Yu and Koltun, 2015]，边界检测 [Xie and Tu, 2015;刘等人，2017]。来自网络不同阶段的响应往往在幅度上存在显着差异。将多尺度激活缩放到相似的大小将有利于以下预测或融合。例如，SSD [Liu et al., 2016] 在进行多尺度预测之前对低级特征图执行 L2 归一化。 [Li et al., 2018] 添加了一个缩放层，用于学习融合尺度，以结合通道注意力和空间注意力输出。在本文中，我们对所有多级激活采用了一个带有归一化器的特征提取器来处理偏差。我们提出的方法还与动态滤波器网络有关 [Jia et al., 2016]，其中基于输入生成特定于样本的滤波器参数。具有特定内核大小的过滤器是动态生成的，以在输入特征图上启用局部空间变换，用作动态卷积内核。相比之下，在我们的方法中，自适应融合权重应用于多级响应图以获得所需的融合输出，并提出了带有归一化器的特征提取器来减轻训练期间的偏差。    

## 具有固定权重的特征融合

在阐述所提出的模型之前，我们首先介绍我们模型中使用的符号，并重新审视 CASENet [Yu et al., 2017] 中的固定权重融合作为初步。 CASENet 采用 ResNet-101 稍作修改来提取多级特征。基于主干，一个 1×1 的卷积层和一个后续的上采样层连接到前三个和顶部的残差块堆栈的输出，产生三个单通道特征图 {Aside1、Aside2、Aside3} 和一个 K-通道类激活图 Aside5 = {A1 side5, ..., AK side5} 分别。这里K是类别的数量。共享连接将底部特征 {Aside1, Aside2, Aside3} 复制 K 次，分别与 Aside5 中的 K 个顶部激活分别连接：Acat = {A1 cat, ..., AK cat}, Ai cat = {Ai side5 , Aside1, Aside2, Aside3}, i ∈ [1,K]。 (1) (2) 得到的连接激活图 Acat 然后被输入到 K-grounped 1 × 1 conv 层以产生具有 K 个通道的融合激活图：Ai fuse=wi 1Ai side5+wi 2Aside1+wi 3Aside2+wi 4Aside3 (3) Afuse = {Ai fuse}, i ∈ [1,K] 其中(wi 1, wi 2, wi 3, wi (4) 4) 是Kgrounped 1×1 conv层的参数，作为融合权重为第 i 个类别。我们省略了方程式中的偏差项。 (3) 为简单起见。更多细节可以参考 [Yu et al., 2017]。