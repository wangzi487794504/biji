### 基于混合 CNN-Transformer 和非局部交叉模态注意力的多模态图像融合

**摘要：**异构传感器拍摄的图像融合有助于丰富信息，提高成像质量。在这篇文章中，我们提出了一个由卷积编码器和基于 Transformer 的解码器组成的混合模型来融合多模态图像。在编码器中，提出了一个非局部交叉模式注意块来捕获多个源图像的局部和全局依赖性。分支融合模块旨在自适应融合两个分支的特征。我们在解码器中嵌入了一个具有线性复杂度的 Transformer 模块，以增强所提出网络的重建能力。通过与现有最先进的融合模型进行比较，定性和定量实验证明了所提出方法的有效性。我们工作的源代码可在 https://github.com/pandayuanyu/HCFusion 获得。

#### 一、简介

多模态图像融合是指结合来自多源图像的互补信息以生成质量提高的融合图像 [1, 2]。例如，可见光图像关注场景纹理的细节，而红外图像则反映物体的温度信息。可见光和红外图像的融合产生了具有丰富细节和显着物体的图像。在医学影像领域，融合多台仪器拍摄的病灶图像有助于更准确的诊断。

特征提取和融合规则是多模态图像融合中的两个核心问题。在过去的几十年里，人们提出了许多传统的方法来解决这两个问题。这些方法可分为多尺度变换 [3, 4]、稀疏表示 [5]、子空间 [6]、混合模型 [7]、基于显着性的 [8] 和其他方法 [1]。尽管这些常规方法在很多情况下可以取得令人满意的结果，但它们往往会削弱源图像的本质特征。

得益于其强大的特征提取和表示能力，深度学习在多模态图像融合中有很多应用。普拉巴卡尔等。 [9] 提出了一种基于卷积的网络，称为 Deepfuse，用于多重曝光图像融合（MEF）。基于 Deepfuse，Li 等人。 [10] 通过用密集块替换特征提取层并重新设计融合策略，提出了可见光和红外图像融合网络 DenseFuse。马等。 [11] 提出了一种基于生成对抗网络 (GAN) 的红外和可见光图像融合框架。许等。 [12] 使用权重块来衡量来自不同源图像的信息的重要性。拉胡德等人。 [13] 提出使用预训练网络提取多模态医学图像的特征图，并使用这些特征图设计权重融合策略。最近，提出了一些将融合与高级视觉任务相结合的研究。唐等。 [14] 提出了 SeAFusion，它弥合了图像融合和语义特征之间的差距。虽然这些方法对大多数融合场景都有效，但它们强调了不同模态图像之间的差异，而没有探索它们之间的相关性。如图 1(d) 所示，Lahoud 等人的方法。 [13] 增强了两种模态中每一种的特征，但也引入了太多琐碎的纹理。

在本文中，我们提出了一种基于混合 CNN-Transformer 架构的网络来融合多模态图像。我们设计了一种非局部跨模态注意机制，通过计算任意两个位置的特征之间的关联来捕获局部和全局依赖性。此外，还探索了一个分支融合模块来自适应地融合两组特征。我们对不同的公开数据集进行了比较实验。定性和定量比较验证了我们的方法相对于其他传统方法的优越性。

####2. 提出的方法。

如图 2 所示，我们的网络采用混合 CNNTransformer 结构，主要由 CNNencoder 和 Transformer 解码器组成。 CNN 编码器负责通过上下文聚合网络 (CAN) [15] 在不丢失空间分辨率的情况下提取多尺度特征，学习不同模态特征之间的关联，并执行自适应融合。

解码器用于重建融合图像。赵等。 [16] 表明混合 Transformer-CNN 架构在模型容量和计算复杂度方面具有更好的性能。受 Swin Transformer [17] 在各种视觉任务中的卓越性能和线性计算复杂度优势的启发，我们在解码器中堆叠了三个 Swin Transformer 块，以提高网络的重建能力。补丁嵌入层降低了特征的维度，以桥接卷积和 Transformer。值得注意的是，在最后一层应用 Tanh 函数的目的是为了限制最终输出中取值的范围。

##### 2.2.非局部跨模态注意力

与仅将自注意力用于一个输入的 [18, 19] 相比，我们将其扩展到具有两个输入的架构以获得两个不同模态之间的连接。如图 2 所示，我们使用通道注意力而不是空间注意力，因为多模态数据已经在空间上对齐良好。对于主模态特征ΦP∈RB×C×H×W和副模态特征ΦV∈RB×C×H×W，跨模态通道注意力操作计算如下：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1672794825017.png" alt="1672794825017" style="zoom:80%;" />

其中ΦVi是位置i处的特征ΦV，ΦPj表示位置j处的特征ΦP。函数 h 计算表示两个特征之间相关性的标量。函数 g 计算位置 j 处的主要输入的表示。 ychannel i 是 ΦP 的每个位置 j (∀j) 处特征归一化聚合的结果，由与位置 i 处的次级输入 ΦV 的相关性加权。

设 Ychannel 为所有位置 i 的跨模态通道注意力算子的集成结果。那么拟议的 NCA 的最终输出是：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1672794873639.png" alt="1672794873639" style="zoom:80%;" />

其中 α 是可学习的参数。

##### 2.3.分支融合模块

为了融合所提出的非局部跨模型注意力块获得的两个特征 Φchannel k (k = 1, 2)（k 表示不同模态特征的分支），我们设计了一种加权分支融合策略。分支 k 的权重计算如下：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1672794939182.png" alt="1672794939182" style="zoom:80%;" />

