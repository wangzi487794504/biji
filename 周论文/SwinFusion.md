##SwinFusion: Cross-domain Long-range Learning for General Image Fusion via Swin Transformer
**摘要：**研究提出了一种新颖的通用图像融合框架基于跨域的远程学习和斯温变压器,称为SwinFusion。一方面,一个attention-guided跨域模块设计实现足够的互补信息的集成和全球互动。更具体地说,该方法涉及一个域间融合单元基于self-attention和interdomain融合单元基于cross-attention,挖掘和整合长在同一个域和跨领域的依赖关系。通过远程依赖关系建模,网络能够完全实现特定领域的信息提取和跨域互补的信息集成以及维护适当的表观强度从全球的角度来看。特别地,我们将改变窗口机制引入到self-attention cross-attention,我们的模型可以得到具有任意大小的图像。另一方面,多场景图像融合问题推广到一个统一的框架和结构维护、细节保护,和适当的强度控制。此外,一个详细的损失函数,由SSIM损失,质地,和强度损失,使网络保持丰富的纹理细节和结构信息,以及提供最佳的表面强度。广泛的实验综合图像融合和数码摄影图像融合证明我们的优越性SwinFusion相比state-of-theart统一的图像融合算法和特定于任务的选择。实现代码和pre-trained权重可以访问https://github.com/Linfeng-Tang/SwinFusion。

### 介绍

归功于硬件设备的限制,信息捕捉到一个单一类型的传感器或单个拍摄设置不能全面描述成像场景[1]。一方面,不同类型的传感器通常从多个角度捕捉特定信息。例如,红外传感器收集热辐射信息,强调突出的目标。可见传感器生成数字图像纹理细节丰富的反射光的信息[2]。近红外传感器可以捕捉补充细节,可能会丢失在可见图像[3]。此外,医学成像领域的结构系统(例如,磁共振成像(MRI)和计算机断层扫描(CT))通常提供结构和解剖信息[4]。相比之下,正电子发射断层扫描(PET)等功能系统可以提供功能信息血流和代谢变化[5]。另一方面,传感器与不同的拍摄设置通常从成像场景获得有限的信息。更具体地说,相机不同的ISO和曝光时间只有抓住动态范围内的信息和不可避免地错过动态范围以外的信息。同样,只与特定的焦距相机捕捉动态中的对象(景深)[6]。值得一提的是,图像或在多个不同传感器捕捉到拍摄设置一般包含互补信息,它鼓励我们这些互补特征合并到一个单独的图像。因此,图像融合技术诞生了。在成像设备的差异方面,图像融合可分为综合图像融合和数字摄影图像融合。示意图说明这两种图像融合的场景展现在图1。单一融合图像与更好的现场表现和视觉感知促进后续实际视觉应用中,如目标检测、跟踪、语义分割、场景理解等。[7]- [9]。

在过去的几十年里,大量的图像融合技术已经被提议,可以大致分为两类,即。特定于任务的图像融合方案[11],[14]和通用图像融合算法[10],[15],[16]。taskspecific图像融合和通用图像融合可以进一步指定为四类,包括传统框架[17]-[19],卷积神经网络(CNN)的框架[20],[21],auto-encoder (AE)的框架[22],[23],生成对抗网络(GAN)的框架[24]- [26]。尽管上述框架可以产生相当大的融合结果,没有一个人可以充分挖掘和整合全局上下文内和跨域。特别是,我们假设由不同的传感器拍摄的图像或在多个光学设置属于不同的领域。一方面,传统的框架通常实现互补信息聚合在空间域[17]或变换域[19],[27],但不可以不相邻像素之间交换信息。因此,传统的框架未能察觉到全球环境。另一方面,CNN的基本组件,AE和GAN-based框架卷积层,我只能接受域内的相互作用。然而,虽然利用本地信息对于图像融合,这些框架不能利用内部或域间长程相关性,进一步提高融合结果。

替代CNN,变压器[28]设计selfattention机制捕捉全球环境之间的相互作用和显示承诺表现在几个视力问题[29]- [33]。尤其是图像融合社区还介绍了变压器模型域间长期依赖并提供竞争融合结果[34]- [37]。尽管如此,仍有一些缺点需要解决。==首先,比起现有的基于变压器方法仅仅探索域间的相互作用,但未能整合跨域情况下,图像融合任务至关重要。第二,视觉变形金刚为图像融合通常请求输入图像,可以重塑一个固定大小(例如,256×256),导致扭曲的场景的融合图像。第三,现有的特定融合场景融合变压器设计没有考虑不同融合任务之间的内在联系。==

为了解决上述挑战,我们设计出一个通用的图像融合框架基于跨域的远程学习和斯温变压器综合图像融合和数码摄影图像融合。我们的设计主要从以下几方面发展。一方面,我们模型所有图像融合场景结构维护、纹理保存,和适当的强度控制。特别是,我们统一形式的损失函数,由SSIM损失,质地,和强度损失,对于所有的融合问题。==所有sub-loss术语遵循相同的建模方式不同的融合任务除了强度损失,这是根据具体融合任务更合适强度的看法。==另一方面,我们设计一个联合CNN-Transformer图像融合框架,我充分源图像的局部和全局依赖关系。CNN-based浅特征提取单元矿山源图像的局部信息。比起的的基于变压器深特征提取单元探索全球浅特性和生成深之间的交互特性包含高层语义信息。然后,精心attention-guided跨域融合模块有效整合内部——深和域间的交互功能。具体来说,域间融合单元聚合全局上下文在同一个域通过selfattention机制。域间融合单元模型远程多个源图像之间的依赖关系和实现全球通过交换查询功能融合,关键,从不同的领域和价值。最后,Transformerbased深功能重建单元和CNN-based融合图像重建单元利用全局和本地信息与优越的视觉认知重构融合图像。值得注意的是,self-attention和cross-attention都(即由转移实现窗口机制。,斯温变压器[38]),它允许我们的框架来处理具有任意大小的输入图像。总之,这项工作可以概括的主要贡献如下:

* 作者提出联合CNN-Transformer融合框架,综合图像融合和数码摄影图像融合。拟议的框架可以充分利用本地和全球信息一体化取得更好的互补特征。
* self-attention-based域间融合单元和一个域间融合crossattention-based单元设计模型和集成远程依赖在同一个域和跨域,分别。
* 多模式图像融合和数码摄影图像融合都是广义结构维护、纹理保存,和适当的强度控制。特别是,一个统一的损失函数形式定义约束所有图像融合问题。
* 大量实验证明我们的框架的优越性而先进的特定于任务和一般融合算法对多模式图像融合和数码摄影图像融合。

### 相关工作

图像融合和远见变压器是两个最相关的技术方法,在这里,我们回顾一些代表性的研究引入他们的发展。

###### 特定于任务的图像融合方法

作为一种重要的图像增强技术,图像融合继续近年来吸引了越来越多的关注。主流的图像融合方案,特别是对特定于任务的图像融合,可以分为以下四种类型的框架。

传统的图像融合框架:传统的融合框架通常实现在空间域和变换域图像融合。一方面,在空间域进行像素级信息集成是传统的图像融合的主要流派之一。GTF[17]红外和可见光图像融合的定义是维护整体强度和纹理结构保存在空间域,并产生了融合图像通过优化目标函数。Awad等人开发了一个自适应可见近红外和可见的空间域的图像融合方案细节增强[3]。此外,刘等人设计了一种基于形态成分分析卷积稀疏模型(CS-MCA)实现医学图像在像素级融合[39]。他们还介绍了局部特征描述符(即。密集的筛选)到multi-focus图像融合任务执行活动水平测量和记录不准确匹配的像素不同源图像之间[40]。另一方面,研究人员还试图将源图像映射到变换域有关的数学变换和手工设计融合规则在变换域实现图像融合。马等人采用结构路径分解技术将源图像在概念上分为三个独立的组件,例如、信号强度、信号结构,意味着强度[41]。然后,多次曝光图像融合实现分别通过合并这三个组件。此外,李等人提出了一种变换域的multi-focus图像融合算法结合稀疏特征矩阵分解和形态滤波技术[42]。

基于CNN图像融合框架:近年来,卷积神经网络(CNN)逐渐成为图像融合的主要的主力,并且表现出显著的优势。CNN的一种形式参与图像融合采用pre-trained网络实现活动水平为手工测量和地图生成一个重量特性[5],[43]。但整个融合过程仍然是基于传统的融合框架,如拉普拉斯金字塔[5]和[43]引导过滤。另一种类型的CNN-based图像融合框架利用CNN学习之间的直接映射源图像和融合图像(或地图)集中在一个端到端的方式[2],[44]。各种研究特定于任务的先验信息集成到CNN-based框架设计损失函数和网络结构。具体地说,马等人提出了一个α-matte边界散焦模型精确模拟散焦效应和传播产生真实数据的训练multi-focus图像融合网络[45]。为了解决困难集中/散焦模糊水平评估的边界,李等人介绍了深回归对学习直接将整个图像转换成二进制面具没有任何补丁操作[46]。赵等人提出了一个depthdistilled multi-focus图像融合方法,考虑到深度线索[47]。他们还关注多样性的特性来提高融合性能[48],[49]。此外,汉等人设计了一个深度知觉增强网络多次曝光图像融合,其中包含两个独立的模块采集内容细节和纠正颜色失真,分别[50]。可见光和红外图像融合,久等人设计了一个聚合残余密集网络相结合的结构优势ResNet和DenseNet CNN的基础上[51]。此外,SeAFusion[7]包含语义约束建模的图像融合,首次提出了一种梯度剩余密度块提高细粒度细节的描述能力。

AE-based图像融合框架:同时,科学家们已经探索auto-encoder-based图像融合框架。具体地说,一个auto-encoder pre-trained采用大规模数据集作为特征提取器和图像再现器,然后专门融合策略是专为深特性来实现图像融合。DeepFuse[13]是这样的先锋融合框架。后来,李等人介绍了密集连接[22]和巢连接[52],[53]加强编码器的特征提取能力。此外,剑等人的注意机制注入AE-based融合框架,加强特征提取的编码器[54]。为了提取特征与更大的可解释性,徐等人量身定做的解开纠结表示AEbased融合框架[11]。然而,所有提到的方法采用手工融合策略,例如,elementwise [13], element-wise体重总和[22],和element-wise最大[20],合并深功能,妨碍融合模型实现最优性能。为此,徐等人设计了一个基于pixel-wise可学的融合规则分类特点和可翻译的重要性评价[23]。

GAN-based图像融合框架:生成对抗网络(GAN)可以有效地模型数据分布即使没有监督信息,它伴随着图像融合的任务。马等人有益地定义了图像融合问题生成器和鉴别器之间的一个游戏。然后,他们甘应用于一系列融合任务,如红外和可见光图像融合[55],multiexposure图像融合[25],multi-focus图像融合[56],pan-sharpening [57]。然而,一个鉴别器未能考虑多个域的数据分布。因此,徐等人提出了dual-discriminator条件生成对抗网络(DDcGAN),利用两个鉴别器约束融合结果的分布。随后,洪等人设计了一个multigenerator multi-discriminator条件生成对抗网络(MGMDcGAN)医学图像融合[26]。此外,李等人多尺度的注意机制注入GAN-based融合框架,鼓励生成器和鉴别器更加注重有意义的区域[58],[59]。

##### 一般的图像融合方法

特定于任务的融合算法能够利用相关的先验来提高融合性能,然而他们忽视了不同的图像融合任务之间的内在关联。因此,越来越多的研究人员正在致力于开发统一的图像融合框架。MST-SR是第一个通用图像融合框架,实现互补信息聚合结合多尺度变换(MST)和稀疏表示(SR)技术[15]。随后,Zhang et al。[20]第一卷积神经网络为通用图像融合设计参照DeepFuse [13]。此外,PMGI[16]作为不同的图像融合问题比例维护梯度和强度,以及设计一个统一的损失函数形式。的基础上PMGI,张等人提出了一个squeeze-and-decomposition网络和一种自适应块决定进一步提高融合性能[60]。此外,赵等人开发了一个通用框架,通过学习特定领域和domain-general multi-realm图像融合特性表征[61]。特别是,考虑到不同的融合场景能促进另一个,徐等人建立了一个统一的无监督图像融合模型multi-fusion任务相结合可学的信息测量体重和弹性整合[10]、[62]。

值得强调的是,特定于任务和一般融合方法都无法充分利用图像的远程交互。换句话说,这些算法只合并互补信息从局部的角度但不能实现全球信息聚合。

##### C. Vision Transformer 

最近,自然语言处理模型,即。变压器[28]已收到很多在计算机视觉界的关注。比起有许多的基于变压器模型,取得了令人印象深刻的性能在不同的视觉任务,如视觉识别[29],[63],[64],对象检测[30],[65],[66],[67],[69]跟踪分割[31],[70],和图像恢复[32],[33],[71]。由于其强大的远程建模能力,变压器也被引入到图像融合[34],[35],[37],[72]。CNN-based融合框架的基础上,对等人设计了一个基于Spatio-Transformer(即多尺度融合策略。,界面张力),参加本地和全球环境[35]。此外,根据AE-based融合框架,福等人取代了CNN与补丁金字塔架构变压器从整个图像中提取非本地信息[37]。然而,auto-encoder只包括变压器不能有效地提取本地信息。为此,赵等人提出了一个顺序DenseNet dual-transformer架构,称为DNDT,提取局部和全局信息,dual-transformer强化了全球信息在特征融合层[72]。此外,瞿等人开发TransMEF[34],注入并联变压器和CNN架构AE-based融合框架,利用self-supervised多任务学习实现多次曝光图像融合。随后,李等人提出了一个convolution-guided变压器可见光和红外图像融合框架(即。CGTF),旨在结合当地特点,CNN和变压器的长期依赖性特性产生更多满意的融合结果[73]。此外,饶等人介绍了变压器到GAN-based融合框架,实现可见光和红外图像融合[36]。

然而,上述融合变压器仅仅是我长期依赖从相同的域(或全球交互)。事实上,跨域远程依赖更相关的图像融合问题。此外,比起大部分的基于变压器融合算法,如itf [35] DNDT [72], TransMEF[34],和CGTF[73],只能处理输入图像与固定大小(例如,256×256)。此外,现有的图像融合视觉变形金刚只解决特定的图像融合问题,但无法解决多模式图像融合和数码摄影图像融合场景融合在一个统一的框架。因此,我们充分探索不同的图像融合场景之间的共性。然后,多模式图像融合和数码摄影图像融合统一建模结构维护、纹理保存,和适当的强度控制。此外,一个attention-guided跨域融合模块旨在有效地挖掘和整合内部和域间全球互动融合的过程。

##### 3方法

在本节中,综合图像融合和数码摄影图像融合是广义结构信息维护、保存纹理细节,和合适的强度控制。我们首先提供总体框架。接下来,提出了统一的损失函数的设计。

######总体框架

让I1和I2∈∈RH W××Cin和RH W××Cin代表两个对齐源图像从不同的领域,如果∈RH W××Cout与完整的场景表示融合图像。H, W和Cin的高度、宽度和通道数量的输入图像。Cout通道数量的融合图像。拟议中的SwinFusion旨在通过合并生成融合图像如果局部和全局源图像中的互补信息I1, I2。如图2中所示,SwinFusion可以分为三个部分:特征提取、attention-guided跨域的融合,和重建。

特征提取:一开始,我们提取浅特性F1科幻和F2科幻的多重卷积层HSE(·)从源图像I1和I2,可表示为: